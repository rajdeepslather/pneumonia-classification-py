{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes to Group:\n",
    "* Normalization and transformations are from hw2 p1\n",
    "* only touched up to classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Pnuenomia Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms,models,datasets\n",
    "from sklearn.metrics import average_precision_score\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms applied to the training data\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std= [0.229, 0.224, 0.225])\n",
    "\n",
    "ds_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "                    transforms.Resize(227),\n",
    "                    transforms.CenterCrop(227),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize\n",
    "                ]),\n",
    "        'test': transforms.Compose([\n",
    "                    transforms.Resize(227),\n",
    "                    transforms.CenterCrop(227),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ]),\n",
    "        'validate': transforms.Compose([\n",
    "                    transforms.Resize(227),\n",
    "                    transforms.CenterCrop(227),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ])\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Train, Test, and Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our pneumonia dataset into our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = {\n",
    "    'train': 'data/train',\n",
    "    'test' : 'data/test',\n",
    "    'validate':  'data/val',\n",
    "}\n",
    "\n",
    "ds_set = {\n",
    "    'train': torchvision.datasets.ImageFolder(ds_dir['train'], ds_transforms['train']),\n",
    "    'test' : torchvision.datasets.ImageFolder(ds_dir['test'], ds_transforms['test']),\n",
    "    'validate':  torchvision.datasets.ImageFolder(ds_dir['validate'], ds_transforms['validate']),\n",
    "}\n",
    "\n",
    "ds_batch_size = 32\n",
    "ds_loader = {\n",
    "    'train': torch.utils.data.DataLoader(ds_set['train'], batch_size=ds_batch_size,shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(ds_set['test'], batch_size=ds_batch_size,shuffle=True),\n",
    "    'validate': torch.utils.data.DataLoader(ds_set['test'], batch_size=ds_batch_size,shuffle=True),\n",
    "}\n",
    "ds_class = {ds_set['validate'].class_to_idx[i]: i for i in list(ds_set['validate'].class_to_idx.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (227, 3, 227) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-55e213e2b5a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#rotate images to be up right\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#show image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mds_figure_subplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#add title of normal or pneumonia\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2682\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2683\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2684\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2685\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2686\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5679\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5681\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 690\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (227, 3, 227) for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAAByCAYAAACP3YV9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAABZ0lEQVR4nO3UMWoDUQxAwf0hR7Dr7P3PYh/CdXIHpTcpvGCT5DFTChWCB1ozs/H/vf32ATyHkBFCRggZIWTE+5Hl0+k0+76/6BQecb1ev2bmfD8/FHLf9+1yuTzvKg5ba91+mnutEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBkhZISQEUJGCBmxZubx5bU+t227ve4cHvAxM+f74aGQ/F1ea4SQEUJGCBkhZISQEUJGCBkhZMQ39zgahbxHHTsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display 8 images\n",
    "num_images = 8\n",
    "\n",
    "ds_iter = iter(ds_loader['train'])\n",
    "images, labels = ds_iter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "#show the images, set up plt\n",
    "ds_figure = plt.figure(figsize=(num_images, 4))\n",
    "\n",
    "for i in np.arange(num_images):\n",
    "    ds_figure_subplot = ds_figure.add_subplot(2, num_images/2, i+1, xticks=[], yticks=[]) #remove ticks and change layout\n",
    "    image = np.transpose(images[i])\n",
    "    image = np.rot90(np.rot90(np.rot90(image)))#rotate images to be up right\n",
    "    \n",
    "    plt.imshow(image) #show image\n",
    "    ds_figure_subplot.set_title(ds_class[labels.tolist()[i]]) #add title of normal or pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(train_loader, classifier, criterion, optimizer):\n",
    "    classifier.train()\n",
    "    loss_ = 0.0\n",
    "    losses = []\n",
    "    for i, (images, labels, _) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = classifier(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "    return torch.stack(losses).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(test_loader, classifier, criterion, print_ind_classes=True):\n",
    "    classifier.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        y_true = np.zeros((0,21))\n",
    "        y_score = np.zeros((0,21))\n",
    "        for i, (images, labels, _) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = classifier(images)\n",
    "            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n",
    "            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n",
    "            loss = criterion(logits, labels)\n",
    "            losses.append(loss)\n",
    "        aps = []\n",
    "        # ignore first class which is background\n",
    "        for i in range(1, y_true.shape[1]):\n",
    "            ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
    "            if print_ind_classes:\n",
    "                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(VOC_CLASSES[i], ap))\n",
    "            aps.append(ap)\n",
    "            \n",
    "        aps = np.array(aps)\n",
    "        mAP = np.mean(aps)\n",
    "        test_loss = torch.mean(torch.stack(losses))\n",
    "        print('mAP: {0:.4f}'.format(mAP))\n",
    "        print('Avg loss: {}'.format(test_loss))\n",
    "        \n",
    "    return mAP, test_loss, aps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the network \n",
    "\n",
    "The network you are given as is will allow you to reach around 0.15-0.2 mAP. To meet the benchmark for this assignment you will need to improve the network. There are a variety of different approaches you should try:\n",
    "\n",
    "* Network architecture changes\n",
    "    * Number of layers: try adding layers to make your network deeper\n",
    "    * Batch normalization: adding batch norm between layers will likely give you a significant performance increase\n",
    "    * Residual connections: as you increase the depth of your network, you will find that having residual connections like those in ResNet architectures will be helpful\n",
    "* Optimizer: Instead of plain SGD, you may want to add a learning rate schedule, add momentum, or use one of the other optimizers you have learned about like Adam. Check the `torch.optim` package for other optimizers\n",
    "* Data augmentation: You should use the `torchvision.transforms` module to try adding random resized crops and horizontal flips of the input data. Check `transforms.RandomResizedCrop` and `transforms.RandomHorizontalFlip` for this\n",
    "* Epochs: Once you have found a generally good hyperparameter setting try training for more epochs\n",
    "* Loss function: You might want to add weighting to the `MultiLabelSoftMarginLoss` for classes that are less well represented or experiment with a different loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier().to(device)\n",
    "# You can can use this function to reload a network you have already saved previously\n",
    "#classifier.load_state_dict(torch.load('voc_classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=45, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch number 1\n",
      "Loss for Training on Epoch 1 is 0.44059082865715027\n",
      "Starting epoch number 2\n",
      "Loss for Training on Epoch 2 is 0.24151358008384705\n",
      "Starting epoch number 3\n",
      "Loss for Training on Epoch 3 is 0.23932667076587677\n",
      "Starting epoch number 4\n",
      "Loss for Training on Epoch 4 is 0.23712097108364105\n",
      "Starting epoch number 5\n",
      "Loss for Training on Epoch 5 is 0.23767206072807312\n",
      "-------  Class: aeroplane        AP:   0.0389  -------\n",
      "-------  Class: bicycle          AP:   0.0708  -------\n",
      "-------  Class: bird             AP:   0.1162  -------\n",
      "-------  Class: boat             AP:   0.0332  -------\n",
      "-------  Class: bottle           AP:   0.0434  -------\n",
      "-------  Class: bus              AP:   0.0345  -------\n",
      "-------  Class: car              AP:   0.1187  -------\n",
      "-------  Class: cat              AP:   0.0811  -------\n",
      "-------  Class: chair            AP:   0.1241  -------\n",
      "-------  Class: cow              AP:   0.0431  -------\n",
      "-------  Class: diningtable      AP:   0.0631  -------\n",
      "-------  Class: dog              AP:   0.0986  -------\n",
      "-------  Class: horse            AP:   0.0698  -------\n",
      "-------  Class: motorbike        AP:   0.0536  -------\n",
      "-------  Class: person           AP:   0.5054  -------\n",
      "-------  Class: pottedplant      AP:   0.0786  -------\n",
      "-------  Class: sheep            AP:   0.0378  -------\n",
      "-------  Class: sofa             AP:   0.0801  -------\n",
      "-------  Class: train            AP:   0.0586  -------\n",
      "-------  Class: tvmonitor        AP:   0.0433  -------\n",
      "mAP: 0.0896\n",
      "Avg loss: 0.23345161974430084\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 5 is 0.08964430141238017\n",
      "val_loss for Testing on Epoch 5 is tensor(0.2335, device='cuda:0')\n",
      "Starting epoch number 6\n",
      "Loss for Training on Epoch 6 is 0.23823301494121552\n",
      "Starting epoch number 7\n",
      "Loss for Training on Epoch 7 is 0.23769360780715942\n",
      "Starting epoch number 8\n",
      "Loss for Training on Epoch 8 is 0.2379249632358551\n",
      "Starting epoch number 9\n",
      "Loss for Training on Epoch 9 is 0.23594312369823456\n",
      "Starting epoch number 10\n",
      "Loss for Training on Epoch 10 is 0.23660477995872498\n",
      "-------  Class: aeroplane        AP:   0.1093  -------\n",
      "-------  Class: bicycle          AP:   0.0875  -------\n",
      "-------  Class: bird             AP:   0.1262  -------\n",
      "-------  Class: boat             AP:   0.0531  -------\n",
      "-------  Class: bottle           AP:   0.0488  -------\n",
      "-------  Class: bus              AP:   0.0380  -------\n",
      "-------  Class: car              AP:   0.1527  -------\n",
      "-------  Class: cat              AP:   0.0821  -------\n",
      "-------  Class: chair            AP:   0.1509  -------\n",
      "-------  Class: cow              AP:   0.0394  -------\n",
      "-------  Class: diningtable      AP:   0.0731  -------\n",
      "-------  Class: dog              AP:   0.1051  -------\n",
      "-------  Class: horse            AP:   0.0729  -------\n",
      "-------  Class: motorbike        AP:   0.0597  -------\n",
      "-------  Class: person           AP:   0.5012  -------\n",
      "-------  Class: pottedplant      AP:   0.0870  -------\n",
      "-------  Class: sheep            AP:   0.0429  -------\n",
      "-------  Class: sofa             AP:   0.0898  -------\n",
      "-------  Class: train            AP:   0.0810  -------\n",
      "-------  Class: tvmonitor        AP:   0.0496  -------\n",
      "mAP: 0.1025\n",
      "Avg loss: 0.23245353996753693\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 10 is 0.10251245365778885\n",
      "val_loss for Testing on Epoch 10 is tensor(0.2325, device='cuda:0')\n",
      "Starting epoch number 11\n",
      "Loss for Training on Epoch 11 is 0.23651590943336487\n",
      "Starting epoch number 12\n",
      "Loss for Training on Epoch 12 is 0.23210477828979492\n",
      "Starting epoch number 13\n",
      "Loss for Training on Epoch 13 is 0.228420689702034\n",
      "Starting epoch number 14\n",
      "Loss for Training on Epoch 14 is 0.225941464304924\n",
      "Starting epoch number 15\n",
      "Loss for Training on Epoch 15 is 0.220551997423172\n",
      "-------  Class: aeroplane        AP:   0.3073  -------\n",
      "-------  Class: bicycle          AP:   0.0929  -------\n",
      "-------  Class: bird             AP:   0.1042  -------\n",
      "-------  Class: boat             AP:   0.1759  -------\n",
      "-------  Class: bottle           AP:   0.0950  -------\n",
      "-------  Class: bus              AP:   0.0672  -------\n",
      "-------  Class: car              AP:   0.2463  -------\n",
      "-------  Class: cat              AP:   0.1305  -------\n",
      "-------  Class: chair            AP:   0.2292  -------\n",
      "-------  Class: cow              AP:   0.0538  -------\n",
      "-------  Class: diningtable      AP:   0.1669  -------\n",
      "-------  Class: dog              AP:   0.1221  -------\n",
      "-------  Class: horse            AP:   0.0746  -------\n",
      "-------  Class: motorbike        AP:   0.0510  -------\n",
      "-------  Class: person           AP:   0.5275  -------\n",
      "-------  Class: pottedplant      AP:   0.0832  -------\n",
      "-------  Class: sheep            AP:   0.0746  -------\n",
      "-------  Class: sofa             AP:   0.1383  -------\n",
      "-------  Class: train            AP:   0.1465  -------\n",
      "-------  Class: tvmonitor        AP:   0.0605  -------\n",
      "mAP: 0.1474\n",
      "Avg loss: 0.22489076852798462\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 15 is 0.14737457443569252\n",
      "val_loss for Testing on Epoch 15 is tensor(0.2249, device='cuda:0')\n",
      "Starting epoch number 16\n",
      "Loss for Training on Epoch 16 is 0.22147363424301147\n",
      "Starting epoch number 17\n",
      "Loss for Training on Epoch 17 is 0.2232542484998703\n",
      "Starting epoch number 18\n",
      "Loss for Training on Epoch 18 is 0.22183021903038025\n",
      "Starting epoch number 19\n",
      "Loss for Training on Epoch 19 is 0.2136915624141693\n",
      "Starting epoch number 20\n",
      "Loss for Training on Epoch 20 is 0.2098955512046814\n",
      "-------  Class: aeroplane        AP:   0.3861  -------\n",
      "-------  Class: bicycle          AP:   0.1207  -------\n",
      "-------  Class: bird             AP:   0.1343  -------\n",
      "-------  Class: boat             AP:   0.2254  -------\n",
      "-------  Class: bottle           AP:   0.1147  -------\n",
      "-------  Class: bus              AP:   0.1335  -------\n",
      "-------  Class: car              AP:   0.3934  -------\n",
      "-------  Class: cat              AP:   0.2493  -------\n",
      "-------  Class: chair            AP:   0.2516  -------\n",
      "-------  Class: cow              AP:   0.0842  -------\n",
      "-------  Class: diningtable      AP:   0.1771  -------\n",
      "-------  Class: dog              AP:   0.1677  -------\n",
      "-------  Class: horse            AP:   0.1761  -------\n",
      "-------  Class: motorbike        AP:   0.1273  -------\n",
      "-------  Class: person           AP:   0.5889  -------\n",
      "-------  Class: pottedplant      AP:   0.1054  -------\n",
      "-------  Class: sheep            AP:   0.1045  -------\n",
      "-------  Class: sofa             AP:   0.1486  -------\n",
      "-------  Class: train            AP:   0.1623  -------\n",
      "-------  Class: tvmonitor        AP:   0.0810  -------\n",
      "mAP: 0.1966\n",
      "Avg loss: 0.21191896498203278\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 20 is 0.19659329053877328\n",
      "val_loss for Testing on Epoch 20 is tensor(0.2119, device='cuda:0')\n",
      "Starting epoch number 21\n",
      "Loss for Training on Epoch 21 is 0.21584978699684143\n",
      "Starting epoch number 22\n",
      "Loss for Training on Epoch 22 is 0.2178301364183426\n",
      "Starting epoch number 23\n",
      "Loss for Training on Epoch 23 is 0.2142748385667801\n",
      "Starting epoch number 24\n",
      "Loss for Training on Epoch 24 is 0.2144838124513626\n",
      "Starting epoch number 25\n",
      "Loss for Training on Epoch 25 is 0.2042277753353119\n",
      "-------  Class: aeroplane        AP:   0.4138  -------\n",
      "-------  Class: bicycle          AP:   0.1398  -------\n",
      "-------  Class: bird             AP:   0.1305  -------\n",
      "-------  Class: boat             AP:   0.2285  -------\n",
      "-------  Class: bottle           AP:   0.1077  -------\n",
      "-------  Class: bus              AP:   0.1308  -------\n",
      "-------  Class: car              AP:   0.4379  -------\n",
      "-------  Class: cat              AP:   0.2647  -------\n",
      "-------  Class: chair            AP:   0.2853  -------\n",
      "-------  Class: cow              AP:   0.0949  -------\n",
      "-------  Class: diningtable      AP:   0.1745  -------\n",
      "-------  Class: dog              AP:   0.2024  -------\n",
      "-------  Class: horse            AP:   0.1994  -------\n",
      "-------  Class: motorbike        AP:   0.1608  -------\n",
      "-------  Class: person           AP:   0.6089  -------\n",
      "-------  Class: pottedplant      AP:   0.1082  -------\n",
      "-------  Class: sheep            AP:   0.0909  -------\n",
      "-------  Class: sofa             AP:   0.1636  -------\n",
      "-------  Class: train            AP:   0.2193  -------\n",
      "-------  Class: tvmonitor        AP:   0.1227  -------\n",
      "mAP: 0.2142\n",
      "Avg loss: 0.20621412992477417\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 25 is 0.21423384175838467\n",
      "val_loss for Testing on Epoch 25 is tensor(0.2062, device='cuda:0')\n",
      "Starting epoch number 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Training on Epoch 26 is 0.20418213307857513\n",
      "Starting epoch number 27\n",
      "Loss for Training on Epoch 27 is 0.20446735620498657\n",
      "Starting epoch number 28\n",
      "Loss for Training on Epoch 28 is 0.1990147978067398\n",
      "Starting epoch number 29\n",
      "Loss for Training on Epoch 29 is 0.20350798964500427\n",
      "Starting epoch number 30\n",
      "Loss for Training on Epoch 30 is 0.20568148791790009\n",
      "-------  Class: aeroplane        AP:   0.4379  -------\n",
      "-------  Class: bicycle          AP:   0.1644  -------\n",
      "-------  Class: bird             AP:   0.1285  -------\n",
      "-------  Class: boat             AP:   0.2120  -------\n",
      "-------  Class: bottle           AP:   0.1300  -------\n",
      "-------  Class: bus              AP:   0.1028  -------\n",
      "-------  Class: car              AP:   0.3968  -------\n",
      "-------  Class: cat              AP:   0.2196  -------\n",
      "-------  Class: chair            AP:   0.2420  -------\n",
      "-------  Class: cow              AP:   0.0817  -------\n",
      "-------  Class: diningtable      AP:   0.1843  -------\n",
      "-------  Class: dog              AP:   0.1599  -------\n",
      "-------  Class: horse            AP:   0.2061  -------\n",
      "-------  Class: motorbike        AP:   0.1475  -------\n",
      "-------  Class: person           AP:   0.6086  -------\n",
      "-------  Class: pottedplant      AP:   0.1206  -------\n",
      "-------  Class: sheep            AP:   0.0573  -------\n",
      "-------  Class: sofa             AP:   0.1359  -------\n",
      "-------  Class: train            AP:   0.2410  -------\n",
      "-------  Class: tvmonitor        AP:   0.1130  -------\n",
      "mAP: 0.2045\n",
      "Avg loss: 0.2130228728055954\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 30 is 0.20450369218563358\n",
      "val_loss for Testing on Epoch 30 is tensor(0.2130, device='cuda:0')\n",
      "Starting epoch number 31\n",
      "Loss for Training on Epoch 31 is 0.19713963568210602\n",
      "Starting epoch number 32\n",
      "Loss for Training on Epoch 32 is 0.1928924322128296\n",
      "Starting epoch number 33\n",
      "Loss for Training on Epoch 33 is 0.19160957634449005\n",
      "Starting epoch number 34\n",
      "Loss for Training on Epoch 34 is 0.19172385334968567\n",
      "Starting epoch number 35\n",
      "Loss for Training on Epoch 35 is 0.19082875549793243\n",
      "-------  Class: aeroplane        AP:   0.4581  -------\n",
      "-------  Class: bicycle          AP:   0.1659  -------\n",
      "-------  Class: bird             AP:   0.1517  -------\n",
      "-------  Class: boat             AP:   0.2401  -------\n",
      "-------  Class: bottle           AP:   0.1202  -------\n",
      "-------  Class: bus              AP:   0.1180  -------\n",
      "-------  Class: car              AP:   0.4596  -------\n",
      "-------  Class: cat              AP:   0.2706  -------\n",
      "-------  Class: chair            AP:   0.3120  -------\n",
      "-------  Class: cow              AP:   0.1666  -------\n",
      "-------  Class: diningtable      AP:   0.2253  -------\n",
      "-------  Class: dog              AP:   0.2021  -------\n",
      "-------  Class: horse            AP:   0.3108  -------\n",
      "-------  Class: motorbike        AP:   0.2004  -------\n",
      "-------  Class: person           AP:   0.6346  -------\n",
      "-------  Class: pottedplant      AP:   0.1331  -------\n",
      "-------  Class: sheep            AP:   0.0903  -------\n",
      "-------  Class: sofa             AP:   0.1882  -------\n",
      "-------  Class: train            AP:   0.2916  -------\n",
      "-------  Class: tvmonitor        AP:   0.1367  -------\n",
      "mAP: 0.2438\n",
      "Avg loss: 0.20845173299312592\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 35 is 0.2438031967006063\n",
      "val_loss for Testing on Epoch 35 is tensor(0.2085, device='cuda:0')\n",
      "Starting epoch number 36\n",
      "Loss for Training on Epoch 36 is 0.19229291379451752\n",
      "Starting epoch number 37\n",
      "Loss for Training on Epoch 37 is 0.18864715099334717\n",
      "Starting epoch number 38\n",
      "Loss for Training on Epoch 38 is 0.18603543937206268\n",
      "Starting epoch number 39\n",
      "Loss for Training on Epoch 39 is 0.1885254681110382\n",
      "Starting epoch number 40\n",
      "Loss for Training on Epoch 40 is 0.19811008870601654\n",
      "-------  Class: aeroplane        AP:   0.4599  -------\n",
      "-------  Class: bicycle          AP:   0.2007  -------\n",
      "-------  Class: bird             AP:   0.1386  -------\n",
      "-------  Class: boat             AP:   0.2460  -------\n",
      "-------  Class: bottle           AP:   0.1205  -------\n",
      "-------  Class: bus              AP:   0.0825  -------\n",
      "-------  Class: car              AP:   0.4646  -------\n",
      "-------  Class: cat              AP:   0.2695  -------\n",
      "-------  Class: chair            AP:   0.3061  -------\n",
      "-------  Class: cow              AP:   0.1136  -------\n",
      "-------  Class: diningtable      AP:   0.2326  -------\n",
      "-------  Class: dog              AP:   0.1930  -------\n",
      "-------  Class: horse            AP:   0.3106  -------\n",
      "-------  Class: motorbike        AP:   0.1888  -------\n",
      "-------  Class: person           AP:   0.6247  -------\n",
      "-------  Class: pottedplant      AP:   0.1140  -------\n",
      "-------  Class: sheep            AP:   0.1044  -------\n",
      "-------  Class: sofa             AP:   0.2046  -------\n",
      "-------  Class: train            AP:   0.3046  -------\n",
      "-------  Class: tvmonitor        AP:   0.1393  -------\n",
      "mAP: 0.2409\n",
      "Avg loss: 0.20575737953186035\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 40 is 0.24094425948134965\n",
      "val_loss for Testing on Epoch 40 is tensor(0.2058, device='cuda:0')\n",
      "Starting epoch number 41\n",
      "Loss for Training on Epoch 41 is 0.18334737420082092\n",
      "Starting epoch number 42\n",
      "Loss for Training on Epoch 42 is 0.18099994957447052\n",
      "Starting epoch number 43\n",
      "Loss for Training on Epoch 43 is 0.1785319596529007\n",
      "Starting epoch number 44\n",
      "Loss for Training on Epoch 44 is 0.17830617725849152\n",
      "Starting epoch number 45\n",
      "Loss for Training on Epoch 45 is 0.17243483662605286\n",
      "-------  Class: aeroplane        AP:   0.4780  -------\n",
      "-------  Class: bicycle          AP:   0.2366  -------\n",
      "-------  Class: bird             AP:   0.1485  -------\n",
      "-------  Class: boat             AP:   0.2546  -------\n",
      "-------  Class: bottle           AP:   0.0923  -------\n",
      "-------  Class: bus              AP:   0.1078  -------\n",
      "-------  Class: car              AP:   0.4873  -------\n",
      "-------  Class: cat              AP:   0.2807  -------\n",
      "-------  Class: chair            AP:   0.3173  -------\n",
      "-------  Class: cow              AP:   0.1424  -------\n",
      "-------  Class: diningtable      AP:   0.1955  -------\n",
      "-------  Class: dog              AP:   0.2084  -------\n",
      "-------  Class: horse            AP:   0.3183  -------\n",
      "-------  Class: motorbike        AP:   0.2502  -------\n",
      "-------  Class: person           AP:   0.6395  -------\n",
      "-------  Class: pottedplant      AP:   0.1253  -------\n",
      "-------  Class: sheep            AP:   0.1042  -------\n",
      "-------  Class: sofa             AP:   0.2163  -------\n",
      "-------  Class: train            AP:   0.3149  -------\n",
      "-------  Class: tvmonitor        AP:   0.1460  -------\n",
      "mAP: 0.2532\n",
      "Avg loss: 0.20409134030342102\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 45 is 0.25319579531736913\n",
      "val_loss for Testing on Epoch 45 is tensor(0.2041, device='cuda:0')\n",
      "Starting epoch number 46\n",
      "Loss for Training on Epoch 46 is 0.16455653309822083\n",
      "Starting epoch number 47\n",
      "Loss for Training on Epoch 47 is 0.1632658690214157\n",
      "Starting epoch number 48\n",
      "Loss for Training on Epoch 48 is 0.16184143722057343\n",
      "Starting epoch number 49\n",
      "Loss for Training on Epoch 49 is 0.16514350473880768\n",
      "Starting epoch number 50\n",
      "Loss for Training on Epoch 50 is 0.16147179901599884\n",
      "-------  Class: aeroplane        AP:   0.4998  -------\n",
      "-------  Class: bicycle          AP:   0.2477  -------\n",
      "-------  Class: bird             AP:   0.1634  -------\n",
      "-------  Class: boat             AP:   0.2304  -------\n",
      "-------  Class: bottle           AP:   0.1114  -------\n",
      "-------  Class: bus              AP:   0.1109  -------\n",
      "-------  Class: car              AP:   0.4877  -------\n",
      "-------  Class: cat              AP:   0.2991  -------\n",
      "-------  Class: chair            AP:   0.3426  -------\n",
      "-------  Class: cow              AP:   0.1554  -------\n",
      "-------  Class: diningtable      AP:   0.2551  -------\n",
      "-------  Class: dog              AP:   0.2199  -------\n",
      "-------  Class: horse            AP:   0.3604  -------\n",
      "-------  Class: motorbike        AP:   0.2574  -------\n",
      "-------  Class: person           AP:   0.6552  -------\n",
      "-------  Class: pottedplant      AP:   0.1322  -------\n",
      "-------  Class: sheep            AP:   0.1166  -------\n",
      "-------  Class: sofa             AP:   0.2246  -------\n",
      "-------  Class: train            AP:   0.3369  -------\n",
      "-------  Class: tvmonitor        AP:   0.1482  -------\n",
      "mAP: 0.2677\n",
      "Avg loss: 0.20085114240646362\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 50 is 0.2677388165491643\n",
      "val_loss for Testing on Epoch 50 is tensor(0.2009, device='cuda:0')\n",
      "Starting epoch number 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Training on Epoch 51 is 0.16307735443115234\n",
      "Starting epoch number 52\n",
      "Loss for Training on Epoch 52 is 0.16401971876621246\n",
      "Starting epoch number 53\n",
      "Loss for Training on Epoch 53 is 0.16016605496406555\n",
      "Starting epoch number 54\n",
      "Loss for Training on Epoch 54 is 0.1600799560546875\n",
      "Starting epoch number 55\n",
      "Loss for Training on Epoch 55 is 0.16180776059627533\n",
      "-------  Class: aeroplane        AP:   0.4940  -------\n",
      "-------  Class: bicycle          AP:   0.2714  -------\n",
      "-------  Class: bird             AP:   0.1709  -------\n",
      "-------  Class: boat             AP:   0.2363  -------\n",
      "-------  Class: bottle           AP:   0.1101  -------\n",
      "-------  Class: bus              AP:   0.1208  -------\n",
      "-------  Class: car              AP:   0.4922  -------\n",
      "-------  Class: cat              AP:   0.2997  -------\n",
      "-------  Class: chair            AP:   0.3360  -------\n",
      "-------  Class: cow              AP:   0.1394  -------\n",
      "-------  Class: diningtable      AP:   0.2480  -------\n",
      "-------  Class: dog              AP:   0.2171  -------\n",
      "-------  Class: horse            AP:   0.3495  -------\n",
      "-------  Class: motorbike        AP:   0.2627  -------\n",
      "-------  Class: person           AP:   0.6523  -------\n",
      "-------  Class: pottedplant      AP:   0.1238  -------\n",
      "-------  Class: sheep            AP:   0.1182  -------\n",
      "-------  Class: sofa             AP:   0.2155  -------\n",
      "-------  Class: train            AP:   0.3272  -------\n",
      "-------  Class: tvmonitor        AP:   0.1490  -------\n",
      "mAP: 0.2667\n",
      "Avg loss: 0.20181530714035034\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 55 is 0.2667125669499689\n",
      "val_loss for Testing on Epoch 55 is tensor(0.2018, device='cuda:0')\n",
      "Starting epoch number 56\n",
      "Loss for Training on Epoch 56 is 0.15739311277866364\n",
      "Starting epoch number 57\n",
      "Loss for Training on Epoch 57 is 0.15879066288471222\n",
      "Starting epoch number 58\n",
      "Loss for Training on Epoch 58 is 0.15787725150585175\n",
      "Starting epoch number 59\n",
      "Loss for Training on Epoch 59 is 0.1573122888803482\n",
      "Starting epoch number 60\n",
      "Loss for Training on Epoch 60 is 0.15607936680316925\n",
      "-------  Class: aeroplane        AP:   0.5086  -------\n",
      "-------  Class: bicycle          AP:   0.2415  -------\n",
      "-------  Class: bird             AP:   0.1685  -------\n",
      "-------  Class: boat             AP:   0.2325  -------\n",
      "-------  Class: bottle           AP:   0.1177  -------\n",
      "-------  Class: bus              AP:   0.1200  -------\n",
      "-------  Class: car              AP:   0.4899  -------\n",
      "-------  Class: cat              AP:   0.2960  -------\n",
      "-------  Class: chair            AP:   0.3366  -------\n",
      "-------  Class: cow              AP:   0.1376  -------\n",
      "-------  Class: diningtable      AP:   0.2564  -------\n",
      "-------  Class: dog              AP:   0.2124  -------\n",
      "-------  Class: horse            AP:   0.3566  -------\n",
      "-------  Class: motorbike        AP:   0.2592  -------\n",
      "-------  Class: person           AP:   0.6528  -------\n",
      "-------  Class: pottedplant      AP:   0.1245  -------\n",
      "-------  Class: sheep            AP:   0.1152  -------\n",
      "-------  Class: sofa             AP:   0.2209  -------\n",
      "-------  Class: train            AP:   0.3428  -------\n",
      "-------  Class: tvmonitor        AP:   0.1469  -------\n",
      "mAP: 0.2668\n",
      "Avg loss: 0.20402128994464874\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 60 is 0.2668367756384834\n",
      "val_loss for Testing on Epoch 60 is tensor(0.2040, device='cuda:0')\n",
      "Starting epoch number 61\n",
      "Loss for Training on Epoch 61 is 0.15396645665168762\n",
      "Starting epoch number 62\n",
      "Loss for Training on Epoch 62 is 0.15420347452163696\n",
      "Starting epoch number 63\n",
      "Loss for Training on Epoch 63 is 0.1534471958875656\n",
      "Starting epoch number 64\n",
      "Loss for Training on Epoch 64 is 0.15751631557941437\n",
      "Starting epoch number 65\n",
      "Loss for Training on Epoch 65 is 0.15674038231372833\n",
      "-------  Class: aeroplane        AP:   0.5048  -------\n",
      "-------  Class: bicycle          AP:   0.2622  -------\n",
      "-------  Class: bird             AP:   0.1705  -------\n",
      "-------  Class: boat             AP:   0.2397  -------\n",
      "-------  Class: bottle           AP:   0.1113  -------\n",
      "-------  Class: bus              AP:   0.1212  -------\n",
      "-------  Class: car              AP:   0.4897  -------\n",
      "-------  Class: cat              AP:   0.2979  -------\n",
      "-------  Class: chair            AP:   0.3430  -------\n",
      "-------  Class: cow              AP:   0.1523  -------\n",
      "-------  Class: diningtable      AP:   0.2671  -------\n",
      "-------  Class: dog              AP:   0.2225  -------\n",
      "-------  Class: horse            AP:   0.3604  -------\n",
      "-------  Class: motorbike        AP:   0.2701  -------\n",
      "-------  Class: person           AP:   0.6521  -------\n",
      "-------  Class: pottedplant      AP:   0.1190  -------\n",
      "-------  Class: sheep            AP:   0.1233  -------\n",
      "-------  Class: sofa             AP:   0.2309  -------\n",
      "-------  Class: train            AP:   0.3325  -------\n",
      "-------  Class: tvmonitor        AP:   0.1507  -------\n",
      "mAP: 0.2711\n",
      "Avg loss: 0.2040313333272934\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 65 is 0.2710655488038757\n",
      "val_loss for Testing on Epoch 65 is tensor(0.2040, device='cuda:0')\n",
      "Starting epoch number 66\n",
      "Loss for Training on Epoch 66 is 0.15061473846435547\n",
      "Starting epoch number 67\n",
      "Loss for Training on Epoch 67 is 0.1492641121149063\n",
      "Starting epoch number 68\n",
      "Loss for Training on Epoch 68 is 0.14786401391029358\n",
      "Starting epoch number 69\n",
      "Loss for Training on Epoch 69 is 0.14960326254367828\n",
      "Starting epoch number 70\n",
      "Loss for Training on Epoch 70 is 0.1485828012228012\n",
      "-------  Class: aeroplane        AP:   0.5080  -------\n",
      "-------  Class: bicycle          AP:   0.2780  -------\n",
      "-------  Class: bird             AP:   0.1729  -------\n",
      "-------  Class: boat             AP:   0.2440  -------\n",
      "-------  Class: bottle           AP:   0.1076  -------\n",
      "-------  Class: bus              AP:   0.1149  -------\n",
      "-------  Class: car              AP:   0.4874  -------\n",
      "-------  Class: cat              AP:   0.3039  -------\n",
      "-------  Class: chair            AP:   0.3461  -------\n",
      "-------  Class: cow              AP:   0.1418  -------\n",
      "-------  Class: diningtable      AP:   0.2610  -------\n",
      "-------  Class: dog              AP:   0.2250  -------\n",
      "-------  Class: horse            AP:   0.3611  -------\n",
      "-------  Class: motorbike        AP:   0.2798  -------\n",
      "-------  Class: person           AP:   0.6521  -------\n",
      "-------  Class: pottedplant      AP:   0.1250  -------\n",
      "-------  Class: sheep            AP:   0.1377  -------\n",
      "-------  Class: sofa             AP:   0.2339  -------\n",
      "-------  Class: train            AP:   0.3395  -------\n",
      "-------  Class: tvmonitor        AP:   0.1486  -------\n",
      "mAP: 0.2734\n",
      "Avg loss: 0.20291449129581451\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 70 is 0.2734157939708592\n",
      "val_loss for Testing on Epoch 70 is tensor(0.2029, device='cuda:0')\n",
      "Starting epoch number 71\n",
      "Loss for Training on Epoch 71 is 0.15440848469734192\n",
      "Starting epoch number 72\n",
      "Loss for Training on Epoch 72 is 0.14780272543430328\n",
      "Starting epoch number 73\n",
      "Loss for Training on Epoch 73 is 0.14600969851016998\n",
      "Starting epoch number 74\n",
      "Loss for Training on Epoch 74 is 0.14457574486732483\n",
      "Starting epoch number 75\n",
      "Loss for Training on Epoch 75 is 0.1452614963054657\n",
      "-------  Class: aeroplane        AP:   0.5058  -------\n",
      "-------  Class: bicycle          AP:   0.2892  -------\n",
      "-------  Class: bird             AP:   0.1766  -------\n",
      "-------  Class: boat             AP:   0.2506  -------\n",
      "-------  Class: bottle           AP:   0.1081  -------\n",
      "-------  Class: bus              AP:   0.1127  -------\n",
      "-------  Class: car              AP:   0.4876  -------\n",
      "-------  Class: cat              AP:   0.2937  -------\n",
      "-------  Class: chair            AP:   0.3407  -------\n",
      "-------  Class: cow              AP:   0.1441  -------\n",
      "-------  Class: diningtable      AP:   0.2540  -------\n",
      "-------  Class: dog              AP:   0.2284  -------\n",
      "-------  Class: horse            AP:   0.3630  -------\n",
      "-------  Class: motorbike        AP:   0.2888  -------\n",
      "-------  Class: person           AP:   0.6477  -------\n",
      "-------  Class: pottedplant      AP:   0.1250  -------\n",
      "-------  Class: sheep            AP:   0.1241  -------\n",
      "-------  Class: sofa             AP:   0.2296  -------\n",
      "-------  Class: train            AP:   0.3268  -------\n",
      "-------  Class: tvmonitor        AP:   0.1474  -------\n",
      "mAP: 0.2722\n",
      "Avg loss: 0.20503707230091095\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 75 is 0.2721827201587739\n",
      "val_loss for Testing on Epoch 75 is tensor(0.2050, device='cuda:0')\n",
      "Starting epoch number 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Training on Epoch 76 is 0.14548037946224213\n",
      "Starting epoch number 77\n",
      "Loss for Training on Epoch 77 is 0.14533841609954834\n",
      "Starting epoch number 78\n",
      "Loss for Training on Epoch 78 is 0.142887145280838\n",
      "Starting epoch number 79\n",
      "Loss for Training on Epoch 79 is 0.1407873034477234\n",
      "Starting epoch number 80\n",
      "Loss for Training on Epoch 80 is 0.1412738561630249\n",
      "-------  Class: aeroplane        AP:   0.5133  -------\n",
      "-------  Class: bicycle          AP:   0.2892  -------\n",
      "-------  Class: bird             AP:   0.1779  -------\n",
      "-------  Class: boat             AP:   0.2422  -------\n",
      "-------  Class: bottle           AP:   0.1028  -------\n",
      "-------  Class: bus              AP:   0.1149  -------\n",
      "-------  Class: car              AP:   0.4904  -------\n",
      "-------  Class: cat              AP:   0.2889  -------\n",
      "-------  Class: chair            AP:   0.3468  -------\n",
      "-------  Class: cow              AP:   0.1414  -------\n",
      "-------  Class: diningtable      AP:   0.2540  -------\n",
      "-------  Class: dog              AP:   0.2274  -------\n",
      "-------  Class: horse            AP:   0.3588  -------\n",
      "-------  Class: motorbike        AP:   0.2878  -------\n",
      "-------  Class: person           AP:   0.6514  -------\n",
      "-------  Class: pottedplant      AP:   0.1232  -------\n",
      "-------  Class: sheep            AP:   0.1408  -------\n",
      "-------  Class: sofa             AP:   0.2337  -------\n",
      "-------  Class: train            AP:   0.3249  -------\n",
      "-------  Class: tvmonitor        AP:   0.1489  -------\n",
      "mAP: 0.2729\n",
      "Avg loss: 0.20691390335559845\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 80 is 0.27292808840979\n",
      "val_loss for Testing on Epoch 80 is tensor(0.2069, device='cuda:0')\n",
      "Starting epoch number 81\n",
      "Loss for Training on Epoch 81 is 0.14242689311504364\n",
      "Starting epoch number 82\n",
      "Loss for Training on Epoch 82 is 0.14499875903129578\n",
      "Starting epoch number 83\n",
      "Loss for Training on Epoch 83 is 0.13771919906139374\n",
      "Starting epoch number 84\n",
      "Loss for Training on Epoch 84 is 0.13825275003910065\n",
      "Starting epoch number 85\n",
      "Loss for Training on Epoch 85 is 0.1408347338438034\n",
      "-------  Class: aeroplane        AP:   0.5128  -------\n",
      "-------  Class: bicycle          AP:   0.2726  -------\n",
      "-------  Class: bird             AP:   0.1800  -------\n",
      "-------  Class: boat             AP:   0.2342  -------\n",
      "-------  Class: bottle           AP:   0.1014  -------\n",
      "-------  Class: bus              AP:   0.1178  -------\n",
      "-------  Class: car              AP:   0.4931  -------\n",
      "-------  Class: cat              AP:   0.2826  -------\n",
      "-------  Class: chair            AP:   0.3515  -------\n",
      "-------  Class: cow              AP:   0.1363  -------\n",
      "-------  Class: diningtable      AP:   0.2555  -------\n",
      "-------  Class: dog              AP:   0.2347  -------\n",
      "-------  Class: horse            AP:   0.3512  -------\n",
      "-------  Class: motorbike        AP:   0.2784  -------\n",
      "-------  Class: person           AP:   0.6469  -------\n",
      "-------  Class: pottedplant      AP:   0.1197  -------\n",
      "-------  Class: sheep            AP:   0.1426  -------\n",
      "-------  Class: sofa             AP:   0.2362  -------\n",
      "-------  Class: train            AP:   0.3345  -------\n",
      "-------  Class: tvmonitor        AP:   0.1518  -------\n",
      "mAP: 0.2717\n",
      "Avg loss: 0.20759770274162292\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 85 is 0.2716804649776613\n",
      "val_loss for Testing on Epoch 85 is tensor(0.2076, device='cuda:0')\n",
      "Starting epoch number 86\n",
      "Loss for Training on Epoch 86 is 0.13850648701190948\n",
      "Starting epoch number 87\n",
      "Loss for Training on Epoch 87 is 0.1384284347295761\n",
      "Starting epoch number 88\n",
      "Loss for Training on Epoch 88 is 0.13724569976329803\n",
      "Starting epoch number 89\n",
      "Loss for Training on Epoch 89 is 0.13704153895378113\n",
      "Starting epoch number 90\n",
      "Loss for Training on Epoch 90 is 0.13685016334056854\n",
      "-------  Class: aeroplane        AP:   0.5131  -------\n",
      "-------  Class: bicycle          AP:   0.2339  -------\n",
      "-------  Class: bird             AP:   0.1605  -------\n",
      "-------  Class: boat             AP:   0.2143  -------\n",
      "-------  Class: bottle           AP:   0.1171  -------\n",
      "-------  Class: bus              AP:   0.1161  -------\n",
      "-------  Class: car              AP:   0.4773  -------\n",
      "-------  Class: cat              AP:   0.2525  -------\n",
      "-------  Class: chair            AP:   0.3461  -------\n",
      "-------  Class: cow              AP:   0.1378  -------\n",
      "-------  Class: diningtable      AP:   0.2594  -------\n",
      "-------  Class: dog              AP:   0.2137  -------\n",
      "-------  Class: horse            AP:   0.3447  -------\n",
      "-------  Class: motorbike        AP:   0.2308  -------\n",
      "-------  Class: person           AP:   0.6496  -------\n",
      "-------  Class: pottedplant      AP:   0.1224  -------\n",
      "-------  Class: sheep            AP:   0.1336  -------\n",
      "-------  Class: sofa             AP:   0.2179  -------\n",
      "-------  Class: train            AP:   0.3306  -------\n",
      "-------  Class: tvmonitor        AP:   0.1531  -------\n",
      "mAP: 0.2612\n",
      "Avg loss: 0.21271100640296936\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 90 is 0.2612226700399292\n",
      "val_loss for Testing on Epoch 90 is tensor(0.2127, device='cuda:0')\n",
      "Starting epoch number 91\n",
      "Loss for Training on Epoch 91 is 0.13440872728824615\n",
      "Starting epoch number 92\n",
      "Loss for Training on Epoch 92 is 0.12788495421409607\n",
      "Starting epoch number 93\n",
      "Loss for Training on Epoch 93 is 0.13190558552742004\n",
      "Starting epoch number 94\n",
      "Loss for Training on Epoch 94 is 0.13389571011066437\n",
      "Starting epoch number 95\n",
      "Loss for Training on Epoch 95 is 0.13402102887630463\n",
      "-------  Class: aeroplane        AP:   0.5130  -------\n",
      "-------  Class: bicycle          AP:   0.2663  -------\n",
      "-------  Class: bird             AP:   0.1723  -------\n",
      "-------  Class: boat             AP:   0.2246  -------\n",
      "-------  Class: bottle           AP:   0.1039  -------\n",
      "-------  Class: bus              AP:   0.1146  -------\n",
      "-------  Class: car              AP:   0.4880  -------\n",
      "-------  Class: cat              AP:   0.2751  -------\n",
      "-------  Class: chair            AP:   0.3455  -------\n",
      "-------  Class: cow              AP:   0.1350  -------\n",
      "-------  Class: diningtable      AP:   0.2526  -------\n",
      "-------  Class: dog              AP:   0.2255  -------\n",
      "-------  Class: horse            AP:   0.3472  -------\n",
      "-------  Class: motorbike        AP:   0.2866  -------\n",
      "-------  Class: person           AP:   0.6516  -------\n",
      "-------  Class: pottedplant      AP:   0.1278  -------\n",
      "-------  Class: sheep            AP:   0.1325  -------\n",
      "-------  Class: sofa             AP:   0.2187  -------\n",
      "-------  Class: train            AP:   0.3325  -------\n",
      "-------  Class: tvmonitor        AP:   0.1512  -------\n",
      "mAP: 0.2682\n",
      "Avg loss: 0.20895454287528992\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 95 is 0.26821894098684984\n",
      "val_loss for Testing on Epoch 95 is tensor(0.2090, device='cuda:0')\n",
      "Starting epoch number 96\n",
      "Loss for Training on Epoch 96 is 0.1279701441526413\n",
      "Starting epoch number 97\n",
      "Loss for Training on Epoch 97 is 0.12883509695529938\n",
      "Starting epoch number 98\n",
      "Loss for Training on Epoch 98 is 0.12887625396251678\n",
      "Starting epoch number 99\n",
      "Loss for Training on Epoch 99 is 0.12851500511169434\n",
      "Starting epoch number 100\n",
      "Loss for Training on Epoch 100 is 0.12968429923057556\n",
      "-------  Class: aeroplane        AP:   0.5138  -------\n",
      "-------  Class: bicycle          AP:   0.2623  -------\n",
      "-------  Class: bird             AP:   0.1745  -------\n",
      "-------  Class: boat             AP:   0.2306  -------\n",
      "-------  Class: bottle           AP:   0.1086  -------\n",
      "-------  Class: bus              AP:   0.1169  -------\n",
      "-------  Class: car              AP:   0.4893  -------\n",
      "-------  Class: cat              AP:   0.2761  -------\n",
      "-------  Class: chair            AP:   0.3449  -------\n",
      "-------  Class: cow              AP:   0.1336  -------\n",
      "-------  Class: diningtable      AP:   0.2562  -------\n",
      "-------  Class: dog              AP:   0.2274  -------\n",
      "-------  Class: horse            AP:   0.3470  -------\n",
      "-------  Class: motorbike        AP:   0.2854  -------\n",
      "-------  Class: person           AP:   0.6492  -------\n",
      "-------  Class: pottedplant      AP:   0.1216  -------\n",
      "-------  Class: sheep            AP:   0.1403  -------\n",
      "-------  Class: sofa             AP:   0.2234  -------\n",
      "-------  Class: train            AP:   0.3321  -------\n",
      "-------  Class: tvmonitor        AP:   0.1561  -------\n",
      "mAP: 0.2695\n",
      "Avg loss: 0.2109023928642273\n",
      "Evaluating classifier\n",
      "Mean Precision Score for Testing on Epoch 100 is 0.26946059336572903\n",
      "val_loss for Testing on Epoch 100 is tensor(0.2109, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Training the Classifier\n",
    "NUM_EPOCHS = 100\n",
    "TEST_FREQUENCY = 5\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    print(\"Starting epoch number \" + str(epoch))\n",
    "    train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n",
    "    print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n",
    "    scheduler.step()\n",
    "    if(epoch%TEST_FREQUENCY==0):\n",
    "        mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n",
    "        print('Evaluating classifier')\n",
    "        print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n",
    "        print(\"val_loss for Testing on Epoch \" +str(epoch) + \" is \"+ str(val_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clssifier network\n",
    "# Suggestion: you can save checkpoints of your network during training and reload them later\n",
    "torch.save(classifier.state_dict(), './voc_classifier.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = VocDataset('VOCdevkit_2007/VOC2007test/','test', test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=False,\n",
    "                                               num_workers=1)\n",
    "\n",
    "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('my_solution.csv', test_aps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
